{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "import seaborn as sns\n",
    "from lightgbm.sklearn import LGBMRegressor, LGBMClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, ElasticNet\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from hashlib import md5\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "mse = make_scorer(mse)\n",
    "mae = make_scorer(mae)\n",
    "r2_score = make_scorer(r2_score)\n",
    "accuracy_score = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlxtend.regressor import StackingRegressor, StackingCVRegressor\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"X_train.csv\")\n",
    "\n",
    "def preprocess_data(data):\n",
    "    def func(str_):\n",
    "        global l\n",
    "        l = eval(str_)\n",
    "        dict_ = dict(zip(*\n",
    "            itertools.chain.from_iterable((x.keys(), x.values()) for x in l)\n",
    "        ))\n",
    "        return dict_\n",
    "\n",
    "    data[\"property\"] = data[\"property\"].apply(lambda str_: dict((list(x.keys())[0], list(x.values())[0]) for x in eval(str_)))\n",
    "    data[\"property\"] = data[\"property\"].apply(lambda x: \" \".join(\"_\".join((str(k), v)) for k, v in x.items()))\n",
    "    data = pd.get_dummies(data, columns=['brandId', 'categoryLevel1Id', 'categoryLevel2Id'])\n",
    "    \n",
    "    data[\"commentNegative\"].fillna(\"EMPTY\", inplace=True)\n",
    "    data[\"commentPositive\"].fillna(\"EMPTY\", inplace=True)\n",
    "\n",
    "    if True:\n",
    "        l = [data]\n",
    "\n",
    "        for col in [\"comment\"]:# , \"commentNegative\", \"commentPositive\"]:\n",
    "            for i, vectorizer in enumerate([\n",
    "                TfidfVectorizer(tokenizer=TweetTokenizer(False).tokenize, ngram_range=(1, 2), min_df=0.01),\n",
    "                TfidfVectorizer(analyzer=\"char\", ngram_range=(1, 4), min_df=0.01)\n",
    "            ]):\n",
    "                count = vectorizer.fit_transform(data[col])\n",
    "\n",
    "                l.append(\n",
    "                    pd.DataFrame(\n",
    "                        count.A,\n",
    "                        columns=[\n",
    "                            col + \" \" + str(i) + \" \" +\n",
    "                            word.replace(\"<\", \"\").replace(\">\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "                            for word in vectorizer.get_feature_names()\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            data.drop(col, axis=1, inplace=True)\n",
    "        data = pd.concat(l, axis=1)\n",
    "    \n",
    "    target = data['reting']\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"]).astype(int)\n",
    "    data.drop(['userName', 'reting', 'sku'], inplace=True, axis=1)\n",
    "    return (data, target)\n",
    "    \n",
    "train, test = train_test_split(data, test_size=0.15)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "train_data, train_target = preprocess_data(train)\n",
    "test_data, test_target = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13248, 11328)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"commentNegative\", \"commentPositive\", \"property\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV]  , MSE=1.7769891501886796, MAE=1.065467169811321, r2_score=-0.021120861371558552, total=  34.8s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "regs = [LGBMRegressor(), XGBRegressor()]\n",
    "reg = StackingRegressor(regs, XGBRegressor())\n",
    "\n",
    "scoring = {\n",
    "    \"MSE\": mse,\n",
    "    \"MAE\": mae,\n",
    "    \"r2_score\": r2_score\n",
    "}\n",
    "\n",
    "cv = cross_validate(KNeighborsRegressor(25), train_data, train_target, scoring=scoring, cv=KFold(10), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = {k: (v.mean(), v.std()) for k, v in cv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv = cross_val_score(SVR(kernel='linear'), train_data, train_target, scoring=mse, cv=KFold(10), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = np.array([len(x) for x in data.sort_values(\"userName\").groupby(\"userName\").groups.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(counts[counts < 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(data.groupby('userName').reting.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[data.loc[x]['reting'].mean() for x in data.groupby(\"userName\").groups.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"property\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data[\"property\"].apply(lambda x: set.union(*[set(a.keys()) for a in eval(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(set.union(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[data['sku'] == 30029584]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[\n",
    "    list(d.keys())[0]\n",
    "    if\n",
    "    hashlib.md5(\"PSP-3008\".encode(\"utf-8\")).hexdigest() in d.values()\n",
    "    else\n",
    "    False \n",
    "    for d in eval(data.loc[14].property)\n",
    "][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[\n",
    "    any(2537 in dd.keys() for dd in eval(d[1].property))\n",
    "    for d in data.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(eval(data.loc[14].property))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data[data['sku'] == data['sku'][0]].property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x[0] == x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "~data[\"commentNegative\"].isnull() & ~data[\"commentPositive\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data[\"commentPositive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
