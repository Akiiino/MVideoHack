{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from pymystem3 import Mystem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train_split.csv\").fillna(\"\")\n",
    "test=pd.read_csv(\"test_split.csv\").fillna(\"\")\n",
    "\n",
    "m = Mystem()\n",
    "\n",
    "def clean(x):\n",
    "    return ''.join(m.lemmatize(re.sub('([^а-яa-z]+)',' ',x.lower()))).strip()\n",
    "\n",
    "df.comment=df.comment.apply(clean)\n",
    "df.commentNegative=df.commentNegative.apply(clean)\n",
    "df.commentPositive=df.commentPositive.apply(clean)\n",
    "\n",
    "test.comment=test.comment.apply(clean)\n",
    "test.commentNegative=test.comment.apply(clean)\n",
    "test.commentPositive=test.comment.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn=Tokenizer(filters=\"\")\n",
    "tkn.fit_on_texts(df.comment+df.commentNegative+df.commentPositive)\n",
    "comments=tkn.texts_to_sequences(df.comment)\n",
    "comments_neg=tkn.texts_to_sequences(df.commentNegative)\n",
    "comments_pos=tkn.texts_to_sequences(df.commentPositive)\n",
    "\n",
    "t_comments=tkn.texts_to_sequences(test.comment)\n",
    "t_comments_neg=tkn.texts_to_sequences(test.commentNegative)\n",
    "t_comments_pos=tkn.texts_to_sequences(test.commentPositive)\n",
    "\n",
    "c_len=int(np.percentile(list(map(len,comments)),95))\n",
    "cneg_len=int(np.percentile(list(map(len,comments_neg)),95))\n",
    "cpos_len=int(np.percentile(list(map(len,comments_pos)),95))\n",
    "\n",
    "c_pad=pad_sequences(comments,c_len)\n",
    "cneg_pad=pad_sequences(comments_neg,cneg_len)\n",
    "cpos_pad=pad_sequences(comments_pos,cpos_len)\n",
    "\n",
    "t_c_pad=pad_sequences(t_comments,c_len)\n",
    "t_cneg_pad=pad_sequences(t_comments_neg,cneg_len)\n",
    "t_cpos_pad=pad_sequences(t_comments_pos,cpos_len)\n",
    "\n",
    "y=((df.reting.values.astype(np.float32))-1)/4\n",
    "t_y=((test.reting.values.astype(np.float32))-1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Concatenate, Dense, Input, Embedding, Bidirectional, AlphaDropout, Masking, GRU\n",
    "\n",
    "comm=Input((c_pad.shape[1],))\n",
    "cneg=Input((cneg_pad.shape[1],))\n",
    "cpos=Input((cpos_pad.shape[1],))\n",
    "\n",
    "m_comm=Masking()(comm)\n",
    "m_cneg=Masking()(cneg)\n",
    "m_cpos=Masking()(cpos)\n",
    "\n",
    "enc_lstm=Bidirectional(LSTM(256,return_sequences=True,dropout=0.2))\n",
    "enc2_lstm=LSTM(256,dropout=0.2)\n",
    "\n",
    "emb=Embedding(len(tkn.word_index)+1,128)\n",
    "\n",
    "comm_emb=emb(m_comm)\n",
    "cneg_emb=emb(m_cneg)\n",
    "cpos_emb=emb(m_cpos)\n",
    "\n",
    "comm_enc=enc_lstm(comm_emb)\n",
    "cneg_enc=enc_lstm(cneg_emb)\n",
    "cpos_enc=enc_lstm(cpos_emb)\n",
    "\n",
    "comm_enc2=enc2_lstm(comm_enc)\n",
    "cneg_enc2=enc2_lstm(cneg_enc)\n",
    "cpos_enc2=enc2_lstm(cpos_enc)\n",
    "\n",
    "conc=Concatenate()([comm_enc2,cneg_enc2,cpos_enc2])\n",
    "\n",
    "# res=Dense(512,activation=\"selu\")(conc)\n",
    "# res=AlphaDropout(0.15)(res)\n",
    "res=Dense(256,activation=\"selu\")(conc)\n",
    "res=AlphaDropout(0.15)(res)\n",
    "res=Dense(128,activation=\"selu\")(res)\n",
    "res=AlphaDropout(0.15)(res)\n",
    "res=Dense(1,activation=\"sigmoid\")(res)\n",
    "\n",
    "model=Model([comm,cneg,cpos],res)\n",
    "model.compile(\"adam\",\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13248 samples, validate on 2339 samples\n",
      "Epoch 1/50\n",
      " 3072/13248 [=====>........................] - ETA: 11s - loss: 0.1859"
     ]
    }
   ],
   "source": [
    "model.fit([c_pad,cneg_pad,cpos_pad],y,batch_size=512,epochs=50,validation_data=([t_c_pad,t_cneg_pad,t_cpos_pad],t_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([c_pad[1].reshape(-1,123),cneg_pad[1],cpos_pad[1].reshape(-1,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
